\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wang2018programmable}
\citation{bartels2019Agile}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces We present a novel method that predicts per pixel depth uncertainity from Monocular/Stereo RGB cameras, uses that information to adaptively place light curtains at regions of low uncertainty, and refines depth estimates over time\relax }}{1}{figure.1}}
\newlabel{fig:teaser}{{1}{1}{We present a novel method that predicts per pixel depth uncertainity from Monocular/Stereo RGB cameras, uses that information to adaptively place light curtains at regions of low uncertainty, and refines depth estimates over time\relax }{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Prior Work}{1}{section.2}}
\citation{Ancha_2020_ECCV}
\@writefile{brf}{\backcite{wang2018programmable}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{bartels2019Agile}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Ancha_2020_ECCV}{{2}{2}{section.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Sensor Setup}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Light Curtain Basics}{2}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The Programmable Light Curtain device, consisting of a steerable laser, an IR camera and a microcontroller, capable of generating a slice in space to image in 3D\relax }}{2}{figure.caption.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Simulator}{2}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Light Curtain Simulator in CARLA environment\relax }}{2}{figure.caption.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Sensor Array}{2}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sensor Array consisting of a Stereo camera pair, the Light Curtain device and a 128 Beam Lidar\relax }}{2}{figure.caption.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Formulation}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Representation}{3}{subsection.4.1}}
\newlabel{eq:d_candi}{{1}{3}{\hskip -1em.~Representation}{equation.4.1}{}}
\newlabel{eq:depth_dist}{{2}{3}{\hskip -1em.~Representation}{equation.4.2}{}}
\newlabel{eq:collapse}{{3}{3}{\hskip -1em.~Representation}{equation.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Our state space consisting of a Depth Probability Volume (DPV) its corrsp Bird's Eye Uncertainty Field (UF)\relax }}{3}{figure.caption.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Curtain Planning}{3}{subsection.4.2}}
\newlabel{eq:constraint}{{4}{3}{\hskip -1em.~Curtain Planning}{equation.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Left: Light Curtain constraint graph subject to max angular velocity of Galvomirror. Right: Placing an optimal curtain along the highest probability region per column of rays\relax }}{3}{figure.caption.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces We look at a depth distribution of one of the rays in UF (yellow line), and figure out where additional curtains (blue points) can be placed such as to maximize information gained. Observe that $m1$ is able to handle multimodal distributions\relax }}{4}{figure.caption.6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:m0m1}{{7}{4}{We look at a depth distribution of one of the rays in UF (yellow line), and figure out where additional curtains (blue points) can be placed such as to maximize information gained. Observe that $m1$ is able to handle multimodal distributions\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Observation Model}{4}{subsection.4.3}}
\newlabel{eq:hmm}{{5}{4}{\hskip -1em.~Observation Model}{equation.4.5}{}}
\newlabel{eq:dist}{{7}{4}{\hskip -1em.~Observation Model}{equation.4.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The effect on the posterior when getting a close to 0 intensity return from the Light Curtain when $z$ is either 1.0 or 0.5\relax }}{4}{figure.caption.7}}
\newlabel{fig:updatemodel}{{8}{4}{The effect on the posterior when getting a close to 0 intensity return from the Light Curtain when $z$ is either 1.0 or 0.5\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Light Curtain only Experiments}{4}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Scenarios (a), (b), (c) from left to right\relax }}{4}{figure.caption.8}}
\newlabel{fig:exp}{{9}{4}{Scenarios (a), (b), (c) from left to right\relax }{figure.caption.8}{}}
\bibstyle{ieee_fullname}
\bibdata{egbib}
\bibcite{Ancha_2020_ECCV}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Doing a simple planar sweep across the scene. Colored pointcloud is the estimated depth, and Lidar ground truth in yellow. Left: LC simulated from the Lidar Depth. Right: Using the real LC\relax }}{5}{figure.caption.9}}
\newlabel{fig:planarsweep}{{10}{5}{Doing a simple planar sweep across the scene. Colored pointcloud is the estimated depth, and Lidar ground truth in yellow. Left: LC simulated from the Lidar Depth. Right: Using the real LC\relax }{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Error wrt to time and number of Sweep steps\relax }}{5}{table.caption.10}}
\newlabel{table:t1}{{1}{5}{Error wrt to time and number of Sweep steps\relax }{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces $\sigma _{c}$ in generated $P\left (\mathbf  {c}_{t}|\mathbf  {d}_{t}\right )$ being fixed vs being dynamic as a function of curtain thickness with real LC\relax }}{5}{table.caption.11}}
\newlabel{table:t2}{{2}{5}{$\sigma _{c}$ in generated $P\left (\mathbf {c}_{t}|\mathbf {d}_{t}\right )$ being fixed vs being dynamic as a function of curtain thickness with real LC\relax }{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces RMSE of Depth in UF over every iteration in scenarios left/(a) right/(b). Note the largely improved performance when low intensities tend to an Inverted Gaussian\relax }}{5}{figure.caption.12}}
\newlabel{fig:figure01}{{11}{5}{RMSE of Depth in UF over every iteration in scenarios left/(a) right/(b). Note the largely improved performance when low intensities tend to an Inverted Gaussian\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {Left:} Policies $m0$ and $m1$ where low intensities result in no information (Uniform Distribution). \textbf  {Right:} Where low intensities result in an Inverted Gaussian based on our Sensor Model\relax }}{5}{figure.caption.13}}
\newlabel{fig:invgau}{{12}{5}{\textbf {Left:} Policies $m0$ and $m1$ where low intensities result in no information (Uniform Distribution). \textbf {Right:} Where low intensities result in an Inverted Gaussian based on our Sensor Model\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Placing more curtains results in faster convergence to the ground truth\relax }}{5}{figure.caption.14}}
\newlabel{fig:figure34}{{13}{5}{Placing more curtains results in faster convergence to the ground truth\relax }{figure.caption.14}{}}
\bibcite{bartels2019Agile}{2}
\bibcite{wang2018programmable}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \textbf  {Above:} Policy $m0$ placing curtains along 3 Locations of a prior distribution from a Monocular Depth Network as seen in the Light Curtain's NIR image. \textbf  {Below:} Starting from a Prior distribution from a Monocular Depth Network leads to faster convergence\relax }}{6}{figure.caption.15}}
\newlabel{fig:prior}{{14}{6}{\textbf {Above:} Policy $m0$ placing curtains along 3 Locations of a prior distribution from a Monocular Depth Network as seen in the Light Curtain's NIR image. \textbf {Below:} Starting from a Prior distribution from a Monocular Depth Network leads to faster convergence\relax }{figure.caption.15}{}}
